[02/07 10:20:42] detectron2 INFO: Rank of current process: 1. World size: 2
[02/07 10:20:47] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.10.12 (main, Aug 15 2025, 14:32:43) [GCC 11.4.0]
numpy                            1.26.4
detectron2                       0.6 @/home/hoangnv/detectron2/detectron2
detectron2._C                    not built correctly: /home/hoangnv/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZNK3c105Error4whatEv
Compiler ($CXX)                  c++ (Ubuntu 11.4.0-1ubuntu1~22.04.2) 11.4.0
CUDA compiler                    Build cuda_11.5.r11.5/compiler.30672275_0
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.1.0+cu121 @/home/hoangnv/.venv/lib/python3.10/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 4090 (arch=8.9)
Driver version                   565.77
CUDA_HOME                        /usr
Pillow                           12.1.0
torchvision                      0.16.0+cu121 @/home/hoangnv/.venv/lib/python3.10/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.11.0
-------------------------------  ------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[02/07 10:20:47] detectron2 INFO: Command line arguments: Namespace(config_file='', resume=True, eval_only=False, num_gpus=2, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50172', opts=[])
[02/07 10:20:47] detectron2.utils.env INFO: Using a generated random seed 51286284
[02/07 10:21:59] detectron2.engine.defaults INFO: Model:
UWSAM(
  (backbone): SAMBackbone(
    (vit): ImageEncoderViT(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1280, kernel_size=(16, 16), stride=(16, 16))
      )
      (blocks): ModuleList(
        (0-31): 32 x CheckpointedBlock(
          (block): Block(
            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (qkv): LoRA_SAM_QKV(
                (qkv): Linear(in_features=1280, out_features=3840, bias=True)
                (lora_A_q): Linear(in_features=1280, out_features=8, bias=False)
                (lora_B_q): Linear(in_features=8, out_features=1280, bias=False)
                (lora_A_v): Linear(in_features=1280, out_features=8, bias=False)
                (lora_B_v): Linear(in_features=8, out_features=1280, bias=False)
                (dropout): Dropout(p=0.05, inplace=False)
              )
              (proj): Linear(in_features=1280, out_features=1280, bias=True)
            )
            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
            (mlp): MLPBlock(
              (lin1): Linear(in_features=1280, out_features=5120, bias=True)
              (lin2): Linear(in_features=5120, out_features=1280, bias=True)
              (act): GELU(approximate='none')
            )
          )
        )
      )
      (neck): Sequential(
        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): LayerNorm2d()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (3): LayerNorm2d()
      )
    )
  )
  (proposal_generator): EUPG(
    (channel_attention): ChannelAttention(
      (avg_pool): AdaptiveAvgPool2d(output_size=1)
      (max_pool): AdaptiveMaxPool2d(output_size=1)
      (fc): Sequential(
        (0): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
        (2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (sigmoid): Sigmoid()
    )
    (multiscale_gen): MultiScaleGenerator(
      (up_p3): Sequential(
        (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
        (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        (2): GELU(approximate='none')
      )
      (up_p2): Sequential(
        (0): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(4, 4))
        (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        (2): GELU(approximate='none')
      )
      (p2_out): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (p3_out): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (p4_out): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (pe_layer): PositionEmbeddingRandom()
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 9, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 36, kernel_size=(1, 1), stride=(1, 1))
    )
    (rpn): RPN(
      (rpn_head): StandardRPNHead(
        (conv): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
          (activation): ReLU()
        )
        (objectness_logits): Conv2d(256, 9, kernel_size=(1, 1), stride=(1, 1))
        (anchor_deltas): Conv2d(256, 36, kernel_size=(1, 1), stride=(1, 1))
      )
      (anchor_generator): DefaultAnchorGenerator(
        (cell_anchors): BufferList()
      )
    )
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (prompt_head): PromptEncoder(
      (conv): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (mlp): Sequential(
        (0): Flatten(start_dim=1, end_dim=-1)
        (1): Linear(in_features=12544, out_features=256, bias=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=256, out_features=256, bias=True)
        (4): ReLU(inplace=True)
        (5): Linear(in_features=256, out_features=2560, bias=True)
      )
    )
    (cls_head): ClassificationHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (mlp): Sequential(
        (0): Linear(in_features=50176, out_features=1024, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=1024, out_features=11, bias=True)
      )
    )
    (box_head): BoxRegressionHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (fc1): Linear(in_features=50176, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (output_layer): Linear(in_features=1024, out_features=4, bias=True)
      (mlp): Sequential(
        (0): Linear(in_features=50176, out_features=1024, bias=True)
        (1): ReLU(inplace=True)
        (2): Linear(in_features=1024, out_features=1024, bias=True)
        (3): ReLU(inplace=True)
        (4): Linear(in_features=1024, out_features=4, bias=True)
      )
    )
  )
  (loss_cls): CrossEntropyLoss()
  (transformer): TwoWayTransformer(
    (layers): ModuleList(
      (0-1): 2 x TwoWayAttentionBlock(
        (self_attn): Attention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (cross_attn_token_to_image): Attention(
          (q_proj): Linear(in_features=256, out_features=128, bias=True)
          (k_proj): Linear(in_features=256, out_features=128, bias=True)
          (v_proj): Linear(in_features=256, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=256, bias=True)
        )
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): MLPBlock(
          (lin1): Linear(in_features=256, out_features=2048, bias=True)
          (lin2): Linear(in_features=2048, out_features=256, bias=True)
          (act): ReLU()
        )
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (cross_attn_image_to_token): Attention(
          (q_proj): Linear(in_features=256, out_features=128, bias=True)
          (k_proj): Linear(in_features=256, out_features=128, bias=True)
          (v_proj): Linear(in_features=256, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=256, bias=True)
        )
      )
    )
    (final_attn_token_to_image): Attention(
      (q_proj): Linear(in_features=256, out_features=128, bias=True)
      (k_proj): Linear(in_features=256, out_features=128, bias=True)
      (v_proj): Linear(in_features=256, out_features=128, bias=True)
      (out_proj): Linear(in_features=128, out_features=256, bias=True)
    )
    (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLPBlock(
            (lin1): Linear(in_features=256, out_features=2048, bias=True)
            (lin2): Linear(in_features=2048, out_features=256, bias=True)
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (pe_layer): PositionEmbeddingRandom()
  (criterion): UWSAMCriterion()
)
[02/07 10:21:59] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [RandomFlip(), ResizeScale(min_scale=0.1, max_scale=2.0, target_height=1024, target_width=1024), FixedSizeCrop(crop_size=(1024, 1024), pad_value=128.0), RandomBrightness(intensity_min=0.9, intensity_max=1.1), RandomContrast(intensity_min=0.9, intensity_max=1.1)]
[02/07 10:22:09] detectron2.data.datasets.coco INFO: Loading /data/bailab_data/hoangnv/UIIS10K/annotations/multiclass_train.json takes 10.82 seconds.
[02/07 10:22:12] detectron2.data.datasets.coco INFO: Loaded 8038 images in COCO format from /data/bailab_data/hoangnv/UIIS10K/annotations/multiclass_train.json
[02/07 10:22:13] detectron2.data.build INFO: Removed 0 images with no usable annotations. 8038 images left.
[02/07 10:22:13] detectron2.data.build INFO: Distribution of instances among all 10 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|    fish    | 17238        |  reptiles  | 290          | arthropoda | 334          |
|   corals   | 9245         |  mollusk   | 1832         |   plants   | 1398         |
|   ruins    | 670          |  garbage   | 630          |   human    | 1511         |
|   robots   | 414          |            |              |            |              |
|   total    | 33562        |            |              |            |              |[0m
[02/07 10:22:13] detectron2.data.build INFO: Using training sampler TrainingSampler
[02/07 10:22:13] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[02/07 10:22:13] detectron2.data.common INFO: Serializing 8038 elements to byte tensors and concatenating them all ...
[02/07 10:22:16] detectron2.data.common INFO: Serialized dataset takes 138.37 MiB
